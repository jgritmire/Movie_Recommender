{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da26ff92",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-11T18:52:39.539773Z",
     "start_time": "2022-04-11T18:52:39.521821Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics.pairwise import (cosine_similarity,\n",
    "                                     euclidean_distances,\n",
    "                                     cosine_distances)\n",
    "\n",
    "from thefuzz import process\n",
    "import fuzzyset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7b596f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-11T18:52:39.948680Z",
     "start_time": "2022-04-11T18:52:39.540771Z"
    }
   },
   "outputs": [],
   "source": [
    "#loading in the movies\n",
    "movies = pd.read_csv('./data/movies_with_review_id.csv')\n",
    "movies.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "movies.rename(columns={'primary_title_x':'primary_title',\n",
    "                       'release_year_x':'release_year'}, inplace=True)\n",
    "movies.set_index('primary_title', inplace=True)\n",
    "\n",
    "#making the tomato score into a float\n",
    "movies['tomato_score'] = movies['tomato_score'].apply(\n",
    "    lambda x: str(x).replace('%','')).astype('float')\n",
    "\n",
    "#making the metacritic score into a float\n",
    "movies['metacritic_score'] = movies['metacritic_score']\\\n",
    "                            .apply(lambda x: eval(x) if x == x else np.nan)\n",
    "\n",
    "#getting dummies for mpaa_rating\n",
    "movies = pd.get_dummies(movies, columns=['mpaa_rating'])\n",
    "\n",
    "movies.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1927ab7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-11T18:52:40.897159Z",
     "start_time": "2022-04-11T18:52:39.949677Z"
    }
   },
   "outputs": [],
   "source": [
    "#the director column got messed up at some point, let's fix it\n",
    "director = pd.read_csv('./data/with_wiki_scrape_complete.csv')\n",
    "director.drop(columns=['Unnamed: 0',\n",
    "                       'title', \n",
    "                       'primary_title', \n",
    "                       'original_title',\n",
    "                       'release_year', \n",
    "                       'runtime', \n",
    "                       'genres', \n",
    "                       'writers', \n",
    "                       'rating',\n",
    "                       'votes', \n",
    "                       'cast_crew', \n",
    "                       'wiki_title', \n",
    "                       'scraped_data', \n",
    "                       'tomato_score',\n",
    "                       'metacritic_score', \n",
    "                       'mpaa_rating', \n",
    "                       'wiki_scrape'\n",
    "                      ], inplace=True)\n",
    "director['directors'] = director['directors'].apply(\\\n",
    "            lambda x: x.replace('nm', '').strip().split(','))\n",
    "\n",
    "#keeping only the primary director for recommendation simplicity\n",
    "director['directors'] = director['directors'].apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f97faac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-11T18:52:40.929074Z",
     "start_time": "2022-04-11T18:52:40.898157Z"
    }
   },
   "outputs": [],
   "source": [
    "#merging director back into the movies df\n",
    "movies.drop(columns=['director_1','director_2', 'director_3'], inplace=True)\n",
    "\n",
    "movies = pd.merge(movies, director, on='tconst', how='left')\n",
    "\n",
    "# # setting the index as title again\n",
    "movies.set_index('primary_title', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0b3f1c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-11T18:52:40.960510Z",
     "start_time": "2022-04-11T18:52:40.930071Z"
    }
   },
   "outputs": [],
   "source": [
    "#filling na's in the tomato and metacritic scores\n",
    "movies['tomato_score'].fillna(movies['rating']*10, inplace=True)\n",
    "movies['metacritic_score'].fillna(movies['rating']/10, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08c3e073",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-11T18:52:40.976466Z",
     "start_time": "2022-04-11T18:52:40.961506Z"
    }
   },
   "outputs": [],
   "source": [
    "#getting complete list of genres from genre_1, 2, and 3\n",
    "genre_list1 = list(pd.DataFrame(movies['genre_1'].value_counts()).\\\n",
    "                                   reset_index()['index'])\n",
    "genre_list2 = list(pd.DataFrame(movies['genre_2'].value_counts()).\\\n",
    "                                   reset_index()['index'])\n",
    "genre_list3 = list(pd.DataFrame(movies['genre_3'].value_counts()).\\\n",
    "                                   reset_index()['index'])\n",
    "\n",
    "for item in genre_list2:\n",
    "    genre_list1.append(item)\n",
    "for item in genre_list3:\n",
    "    genre_list1.append(item)\n",
    "    \n",
    "genre_list=set(genre_list1)\n",
    "#genre_list now contains all of the possible genre tags so we can start creating dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90d38a1e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-11T18:53:51.396818Z",
     "start_time": "2022-04-11T18:52:40.977464Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jg_ri\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1637: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    }
   ],
   "source": [
    "#creating the blank dummy columns\n",
    "for genre in genre_list:\n",
    "    movies[genre] = 0\n",
    "\n",
    "#populating the dummy columns\n",
    "for i in range(0, len(list(movies['genre_1']))):\n",
    "    for genre in genre_list:\n",
    "        if movies['genre_1'].iloc[i] == genre:\n",
    "            movies[genre].iloc[i] = 1\n",
    "        elif movies['genre_2'].iloc[i] == genre:\n",
    "            movies[genre].iloc[i] = 1\n",
    "        elif movies['genre_3'].iloc[i] == genre:\n",
    "            movies[genre].iloc[i] = 1\n",
    "        else:\n",
    "            movies[genre].iloc[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f011ae95",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-11T18:53:51.412776Z",
     "start_time": "2022-04-11T18:53:51.397816Z"
    }
   },
   "outputs": [],
   "source": [
    "movies3 = movies.drop(columns=['genre_1','genre_2','genre_3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55657a42",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-11T18:53:51.492562Z",
     "start_time": "2022-04-11T18:53:51.413774Z"
    }
   },
   "outputs": [],
   "source": [
    "#creating a function to add the necessary zeroes back onto the cast identifiers\n",
    "def add_zeroes(identifier):\n",
    "    number_of_zeroes = 8 - len(str(identifier))\n",
    "    return (number_of_zeroes * '0') + str(identifier)\n",
    "\n",
    "#apply the zeroes function to all 10 cast columns, and writer columns\n",
    "for i in range(1, 11):\n",
    "    movies3['cast_' + str(i)] = movies3['cast_' + str(i)].apply(add_zeroes)\n",
    "   \n",
    "for i in range(1, 4):\n",
    "    movies3['writer_' + str(i)] = movies3['writer_' + str(i)].apply(add_zeroes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25eb0505",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-11T18:53:52.144817Z",
     "start_time": "2022-04-11T18:53:51.493560Z"
    }
   },
   "outputs": [],
   "source": [
    "#getting dummies for the writers columns\n",
    "\n",
    "for i in range(1, 4):\n",
    "    movies3 = pd.get_dummies(movies3, columns=['writer_'+str(i)])\n",
    "    \n",
    "#creating a list of all the writers ids:\n",
    "writer_ids = []\n",
    "for column_name in movies3.columns:\n",
    "    if column_name[:6] == 'writer':\n",
    "        writer_ids.append(column_name[9:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9da65c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-11T18:55:39.065331Z",
     "start_time": "2022-04-11T18:53:52.145815Z"
    }
   },
   "outputs": [],
   "source": [
    "#doing horizontal summations to get a single column for each writer\n",
    "writer_df = pd.DataFrame()\n",
    "for writer_id in writer_ids:\n",
    "    temp_list = []\n",
    "    for column_name in movies3.columns:\n",
    "        if str(column_name[9:]) == str(writer_id):\n",
    "            temp_list.append(column_name)\n",
    "    temp_df = pd.DataFrame()\n",
    "    temp_df[writer_id] = movies3[temp_list].sum(axis=1)\n",
    "    writer_df['writer_id_'+ str(writer_id)] = temp_df[writer_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34805912",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-11T18:56:17.680318Z",
     "start_time": "2022-04-11T18:55:39.066329Z"
    }
   },
   "outputs": [],
   "source": [
    "#taking the new and improved writers columns and adding them to the old df\n",
    "\n",
    "for column_name in writer_df.columns:\n",
    "    movies[column_name] = list(writer_df[column_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499a36ef",
   "metadata": {},
   "source": [
    "While I do believe that the cast columns could improve the performance of the recommender, they ultimately slow down the whole process too much for me to iteratively test my code and model, so I have commented out the related cells below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da147344",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-11T18:56:25.473142Z",
     "start_time": "2022-04-11T18:56:17.681317Z"
    }
   },
   "outputs": [],
   "source": [
    "#getting dummies for the cast columns\n",
    "\n",
    "for i in range(1, 11):\n",
    "    movies3 = pd.get_dummies(movies3, columns=['cast_'+str(i)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e7c7e4a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-11T18:56:25.504565Z",
     "start_time": "2022-04-11T18:56:25.475136Z"
    }
   },
   "outputs": [],
   "source": [
    "#creating a list of all the cast ids:\n",
    "cast_ids = []\n",
    "for column_name in movies3.columns:\n",
    "    if column_name[:4] == 'cast':\n",
    "        cast_ids.append(column_name[7:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93d6786",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-04-11T18:52:39.534Z"
    }
   },
   "outputs": [],
   "source": [
    "#doing horizontal summations to get a single column for each cast member\n",
    "cast_df = pd.DataFrame()\n",
    "for cast_id in cast_ids:\n",
    "    temp_list = []\n",
    "    for column_name in movies3.columns:\n",
    "        if str(column_name[7:]) == str(cast_id):\n",
    "            temp_list.append(column_name)\n",
    "    temp_df = pd.DataFrame()\n",
    "    temp_df[cast_id] = movies3[temp_list].sum(axis=1)\n",
    "    cast_df['cast_id_'+ str(cast_id)] = temp_df[cast_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7635ba04",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-04-11T18:52:39.535Z"
    }
   },
   "outputs": [],
   "source": [
    "#taking the new and improved cast columns and adding them to the old df\n",
    "\n",
    "for column_name in cast_df.columns:\n",
    "    movies[column_name] = list(cast_df[column_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1327cbd6",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-04-11T18:52:39.536Z"
    }
   },
   "outputs": [],
   "source": [
    "movies.to_csv('./data/recommender_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70203d7",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-04-11T18:52:39.537Z"
    }
   },
   "outputs": [],
   "source": [
    "#Dropping columns that we will not be considering in our recommendations\n",
    "movies2 = movies.drop(columns=['genre_1', \n",
    "                     'genre_2', \n",
    "                     'genre_3', \n",
    "                     'writer_1', \n",
    "                     'writer_2', \n",
    "                     'writer_3', \n",
    "                     'cast_1',\n",
    "                     'cast_2',\n",
    "                    'cast_3',\n",
    "                    'cast_4',\n",
    "                    'cast_5',\n",
    "                    'cast_6',\n",
    "                    'cast_7',\n",
    "                    'cast_8',\n",
    "                    'cast_9',\n",
    "                    'cast_10',\n",
    "                    'plot',\n",
    "#                     'tconst',\n",
    "                    'movieId',\n",
    "                    'votes'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c678dbec",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-04-11T18:52:39.537Z"
    }
   },
   "outputs": [],
   "source": [
    "movies2 = pd.get_dummies(movies2, columns=['directors'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3152dbd5",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-04-11T18:52:39.538Z"
    }
   },
   "outputs": [],
   "source": [
    "movies2.drop_duplicates(keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29c5c61",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-04-11T18:52:39.539Z"
    }
   },
   "outputs": [],
   "source": [
    "movies = movies2.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bf980b",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-04-11T18:52:39.540Z"
    }
   },
   "outputs": [],
   "source": [
    "movies2.set_index('tconst', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86c3a57",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-04-11T18:52:39.541Z"
    }
   },
   "outputs": [],
   "source": [
    "cos_df = pd.DataFrame(cosine_similarity(movies2, movies2),\n",
    "                                columns=movies2.index,\n",
    "                                index=movies2.index)\n",
    "\n",
    "cos_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83019d6f",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-04-11T18:52:39.542Z"
    }
   },
   "outputs": [],
   "source": [
    "cos_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82af0cff",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-04-11T18:52:39.543Z"
    }
   },
   "outputs": [],
   "source": [
    "#getting the top 20 recommended movies for a movie (excluding the film itself)\n",
    "list(cos_df.sort_values('tt1657299', ascending=False)['tconst'][1:21])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8f619d",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-04-11T18:52:39.545Z"
    }
   },
   "outputs": [],
   "source": [
    "euc_df = pd.DataFrame(euclidean_distances(movies2, movies2), \n",
    "             columns=movies2.index, \n",
    "             index=movies2.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf00901f",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-04-11T18:52:39.546Z"
    }
   },
   "outputs": [],
   "source": [
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2de294",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-04-11T18:52:39.548Z"
    }
   },
   "outputs": [],
   "source": [
    "movies2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ce72df",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-04-11T18:52:39.549Z"
    }
   },
   "outputs": [],
   "source": [
    "#getting a list of all the unique identifiers from movies2 that we can recommned\n",
    "movie_id = pd.DataFrame(list(movies2.index), columns=['tconst'])\n",
    "\n",
    "#joining the titles back on to the id's\n",
    "movie_id = pd.merge(movie_id, movies, on='tconst', how='left')\n",
    "\n",
    "#restricting to just ID and title\n",
    "movie_id = movie_id[['tconst','primary_title', 'release_year']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22692aef",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-04-11T18:52:39.550Z"
    }
   },
   "outputs": [],
   "source": [
    "#creating a column with title and release year for clarification purposes later\n",
    "\n",
    "movie_id['release_year'] = \\\n",
    "movie_id['release_year'].apply(lambda x: ' (' + str(x) + ')')\n",
    "\n",
    "movie_id['full_title'] = \\\n",
    "movie_id.apply(lambda row: row['primary_title'] + row['release_year'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474847ae",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-04-11T18:52:39.551Z"
    }
   },
   "outputs": [],
   "source": [
    "movie_id.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81f56fd",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-04-11T18:52:39.552Z"
    }
   },
   "outputs": [],
   "source": [
    "movie_id.to_csv('./data/movie_ids_and_year.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b077f2",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-04-11T18:52:39.552Z"
    }
   },
   "outputs": [],
   "source": [
    "cos_df.to_csv('./data/product_based_recommender_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a9f26e",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-04-11T18:52:39.553Z"
    }
   },
   "outputs": [],
   "source": [
    "#creating the list of titles for fuzzy matching\n",
    "title_list = fuzzyset.FuzzySet(list(movie_id['full_title']))\n",
    "\n",
    "def intersection(list1, list2):\n",
    "    return [item for item in list1 if item in list2]\n",
    "\n",
    "def new_user_recommender():\n",
    "    correct = 'n'\n",
    "    \n",
    "    while correct != 'y':\n",
    "        \n",
    "        #asking the user to input films they like\n",
    "        liked_films = input(\"Please enter 3 film titles that you enjoy, \\nseparated by forward slashes (/):\\n\")\n",
    "\n",
    "        if len(liked_films.split('/')) == 3:\n",
    "            #getting the matching film titles from our list of films\n",
    "            film1 = liked_films.split('/')[0]\n",
    "            film2 = liked_films.split('/')[1]\n",
    "            film3 = liked_films.split('/')[2]\n",
    "\n",
    "            #appending the matching titles to a list\n",
    "            liked_films = []\n",
    "            liked_films.append(title_list.get(film1)[0][1])\n",
    "            liked_films.append(title_list.get(film2)[0][1])\n",
    "            liked_films.append(title_list.get(film3)[0][1])\n",
    "\n",
    "            #printing the list of films for validation\n",
    "            print('')\n",
    "            for film in liked_films:\n",
    "                print(film)\n",
    "\n",
    "            #asking the user to validate the selected list of films\n",
    "            correct = input(\"Please verify that the above titles are correct y/n:\\n\")\n",
    "        \n",
    "        else:\n",
    "            correct = 'n'\n",
    "            print('Error, please try again')\n",
    "        \n",
    "#creating the list of suggestions for the three selected titles\n",
    "\n",
    "    #getting the unique ids for the liked movies:\n",
    "    liked_films_tconst = []\n",
    "    for film in liked_films:\n",
    "        liked_films_tconst.append(\\\n",
    "            movie_id[movie_id['full_title'] == film]['tconst'].values[0])\n",
    "    \n",
    "    #getting the top 20 recommended films for each liked movie\n",
    "    rec_list_1 = list(cos_df.sort_values(liked_films_tconst[0], ascending=False)\\\n",
    "                      ['tconst'][1:21])\n",
    "    rec_list_2 = list(cos_df.sort_values(liked_films_tconst[1], ascending=False)\\\n",
    "                      ['tconst'][1:21])\n",
    "    rec_list_3 = list(cos_df.sort_values(liked_films_tconst[2], ascending=False)\\\n",
    "                      ['tconst'][1:21])\n",
    "    \n",
    "    #translating the tconst back to titles\n",
    "    rec_list_1_titles = []\n",
    "    rec_list_2_titles = []\n",
    "    rec_list_3_titles = []\n",
    "    \n",
    "    for tconst in rec_list_1:\n",
    "        rec_list_1_titles.append(\\\n",
    "            list(movie_id[movie_id['tconst'] == tconst]['full_title'])[0])\n",
    "        \n",
    "    for tconst in rec_list_2:\n",
    "        rec_list_2_titles.append(\\\n",
    "            list(movie_id[movie_id['tconst'] == tconst]['full_title'])[0])\n",
    "        \n",
    "    for tconst in rec_list_3:\n",
    "        rec_list_3_titles.append(\\\n",
    "            list(movie_id[movie_id['tconst'] == tconst]['full_title'])[0])\n",
    "    \n",
    "    #if there are films that are recommended based on more than 1 liked movie\n",
    "    #prioritize these films\n",
    "    final_recs = intersection(rec_list_1_titles, rec_list_2_titles)\n",
    "    final_recs = intersection(final_recs, rec_list_3_titles)\n",
    "    \n",
    "    #only want to return 5 recommendations\n",
    "    for i in range(0, 5):\n",
    "        final_recs.extend([rec_list_1_titles[i],\\\n",
    "                            rec_list_2_titles[i],\\\n",
    "                            rec_list_3_titles[i]])\n",
    "           \n",
    "    print(final_recs[0], '\\n', \n",
    "          final_recs[1], '\\n',\n",
    "          final_recs[2], '\\n',\n",
    "          final_recs[3], '\\n',\n",
    "          final_recs[4]\n",
    "         )\n",
    "    \n",
    "    #asking the user to \"rate\" the films that we have recommended to see if we're doing well\n",
    "    bad_format = 'y'\n",
    "    \n",
    "    while bad_format == 'y':\n",
    "        film_reviews = input('Please rate the above films on how likely you are to watch them (1-5). Separate the scores with commas, \\n')\n",
    "        film_reviews = film_reviews.replace(' ','').split(',')\n",
    "        for i in range(0, len(film_reviews)):\n",
    "            film_reviews[i] = int(film_reviews[i])\n",
    "        \n",
    "         #checking to see if they have input their scores correctly\n",
    "        if all(isinstance(x, int) for x in film_reviews) == True\\\n",
    "        and len(film_reviews) == 5\\\n",
    "        and min(film_reviews) >= 1\\\n",
    "        and max(film_reviews) <= 5:\n",
    "            print('Thank You!')\n",
    "            break\n",
    "        else:\n",
    "            bad_format = 'y'\n",
    "            \n",
    "    #saving their review scores to the reviews data frame for review based recs\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0321f8",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-04-11T18:52:39.554Z"
    }
   },
   "outputs": [],
   "source": [
    "new_user_recommender()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5490f4f",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-04-11T18:52:39.555Z"
    }
   },
   "outputs": [],
   "source": [
    "# building a person to person recommender\n",
    "\n",
    "#import the ratings dataframe\n",
    "ratings = pd.read_csv('./data/ml-25m/ml-25m/ratings.csv')\n",
    "ratings.drop(columns=['timestamp'], inplace=True)\n",
    "\n",
    "#import the unique id/title for each film\n",
    "movie_ids = pd.read_csv('./data/movies_with_review_id.csv')\n",
    "movie_ids = movie_ids[['tconst', 'primary_title_x','movieId']]\n",
    "\n",
    "#limiting the ratings df to only the films that are in our movies database\n",
    "ratings = ratings[ratings['movieId'].isin(list(movie_ids['movieId']))]\n",
    "\n",
    "#joining film titles onto the ratings df\n",
    "ratings = pd.merge(ratings, movie_ids, on='movieId', how='left') \n",
    "\n",
    "ratings.rename(columns={'primary_title_x':'primary_title'}, inplace=True)\n",
    "\n",
    "ratings.drop(columns=['primary_title', 'movieId'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728941d1",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-04-11T18:52:39.556Z"
    }
   },
   "outputs": [],
   "source": [
    "#transforming the ratings dataframe into the required format\n",
    "ratings = pd.pivot_table(\n",
    "    ratings, \n",
    "    values = 'rating',\n",
    "    columns = 'tconst',\n",
    "    index = 'userId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfb346b",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-04-11T18:52:39.557Z"
    }
   },
   "outputs": [],
   "source": [
    "# ratings.T #fit a standar scaler to this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5e9620",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-04-11T18:52:39.558Z"
    }
   },
   "outputs": [],
   "source": [
    "ratings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411ba0db",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-04-11T18:52:39.558Z"
    }
   },
   "outputs": [],
   "source": [
    "#normalizing each users reviews, as seen in our recommenders lesson\n",
    "\n",
    "ratings_std = pd.DataFrame(index=ratings.index, columns = ratings.columns )\n",
    "\n",
    "# We're basically implementing a StandardScaler that can handle nans here...\n",
    "def stand(x, ave, std):\n",
    "    try:\n",
    "        return (x-ave) / std\n",
    "\n",
    "    except:\n",
    "        return x\n",
    "    \n",
    "for u in ratings.index:\n",
    "    ave = np.mean(ratings.loc[u,:])\n",
    "    std = np.std(ratings.loc[u,:])\n",
    "    \n",
    "    ratings_std.loc[u,:] = ratings.loc[u,:].apply(lambda x: stand(x, ave, std))\n",
    "    \n",
    "ratings_std = ratings_std + 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e20ad1",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-04-11T18:52:39.559Z"
    }
   },
   "outputs": [],
   "source": [
    "# function to calculate similarity between any two users\n",
    "# if they have fewer than n films in common, it'll return 0\n",
    "def sim(user1, user2, n):\n",
    "    #grabbing movies that the two users have in common, dropping movies that have not been reviewed\n",
    "    commons = ratings.loc[[user1,user2]].dropna(axis=1)\n",
    "    #if they have less than n movies in common, return 0\n",
    "    if len(commons.columns)<n:\n",
    "        return 0\n",
    "    else:\n",
    "        #if they have more than n columns in common, return the cos similarity of the two users\n",
    "        return cosine_similarity(commons.loc[user1,:].values.reshape(1,-1), \\\n",
    "                                 commons.loc[user2,:].values.reshape(1,-1))[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855abb0f",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-04-11T18:52:39.561Z"
    }
   },
   "outputs": [],
   "source": [
    "# calculates estimated rating for a user + new film\n",
    "def rating_estimator(user, title):\n",
    "#     '''doesnt check if user has seen title.  \n",
    "#     assumes we are only asking about unseen titles'''\n",
    "    \n",
    "    #list of users id's of people that have reviewed a title\n",
    "    seers = list(ratings[title].dropna().index)\n",
    "    \n",
    "    #corresponding ratings for each user above, for a specified title\n",
    "    reviews = list(ratings[title].dropna().values) \n",
    "    \n",
    "    #create empty container\n",
    "    sims = []\n",
    "    \n",
    "    #iterate over the list of people that have viewed a title\n",
    "    for s in seers:\n",
    "        \n",
    "#        append similarities between new user and users who have seen the title\n",
    "        sims.append(sim(user,s,10))\n",
    "# score of how similar user and s are, weighted by how much seers liked the movie\n",
    "#will help get the recommendation \n",
    "    return np.sum([i*j for i, j in zip(reviews, sims)]) / np.sum(sims) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2ec869",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-04-11T18:52:39.562Z"
    }
   },
   "outputs": [],
   "source": [
    "rating_estimator(1, 'tt0033373')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab235779",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-04-11T18:52:39.564Z"
    }
   },
   "outputs": [],
   "source": [
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c2a90e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
